{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from ta.momentum import RSIIndicator\n",
    "from collections import deque\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering the data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the initial data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main ticker to predict\n",
    "TICKER_TO_PREDICT = \"SPY\"\n",
    "# Supplementary tickers to help prediction\n",
    "INDICATOR_TICKERS = [\"QQQ\", \"^TNX\", \"^VIX\", \"CL=F\"]\n",
    "\n",
    "# The last day which the training data should include\n",
    "TRAIN_DATA_END_DATE = datetime.datetime(2023, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY_Open</th>\n",
       "      <th>SPY_High</th>\n",
       "      <th>SPY_Low</th>\n",
       "      <th>SPY_Close</th>\n",
       "      <th>SPY_Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-01-29</th>\n",
       "      <td>43.968750</td>\n",
       "      <td>43.968750</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>43.937500</td>\n",
       "      <td>1003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-01</th>\n",
       "      <td>43.968750</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>43.968750</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-02</th>\n",
       "      <td>44.218750</td>\n",
       "      <td>44.375000</td>\n",
       "      <td>44.125000</td>\n",
       "      <td>44.343750</td>\n",
       "      <td>201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-03</th>\n",
       "      <td>44.406250</td>\n",
       "      <td>44.843750</td>\n",
       "      <td>44.375000</td>\n",
       "      <td>44.812500</td>\n",
       "      <td>529400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-04</th>\n",
       "      <td>44.968750</td>\n",
       "      <td>45.093750</td>\n",
       "      <td>44.468750</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>531500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-26</th>\n",
       "      <td>406.720001</td>\n",
       "      <td>407.839996</td>\n",
       "      <td>403.779999</td>\n",
       "      <td>404.359985</td>\n",
       "      <td>80447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>407.000000</td>\n",
       "      <td>412.690002</td>\n",
       "      <td>406.739990</td>\n",
       "      <td>412.410004</td>\n",
       "      <td>92968400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28</th>\n",
       "      <td>411.489990</td>\n",
       "      <td>415.940002</td>\n",
       "      <td>411.429993</td>\n",
       "      <td>415.929993</td>\n",
       "      <td>89335600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>415.470001</td>\n",
       "      <td>417.619995</td>\n",
       "      <td>415.269989</td>\n",
       "      <td>415.510010</td>\n",
       "      <td>62122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>414.769989</td>\n",
       "      <td>414.820007</td>\n",
       "      <td>407.820007</td>\n",
       "      <td>410.839996</td>\n",
       "      <td>103998500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7619 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SPY_Open    SPY_High     SPY_Low   SPY_Close  SPY_Volume\n",
       "Date                                                                  \n",
       "1993-01-29   43.968750   43.968750   43.750000   43.937500     1003200\n",
       "1993-02-01   43.968750   44.250000   43.968750   44.250000      480500\n",
       "1993-02-02   44.218750   44.375000   44.125000   44.343750      201300\n",
       "1993-02-03   44.406250   44.843750   44.375000   44.812500      529400\n",
       "1993-02-04   44.968750   45.093750   44.468750   45.000000      531500\n",
       "...                ...         ...         ...         ...         ...\n",
       "2023-04-26  406.720001  407.839996  403.779999  404.359985    80447000\n",
       "2023-04-27  407.000000  412.690002  406.739990  412.410004    92968400\n",
       "2023-04-28  411.489990  415.940002  411.429993  415.929993    89335600\n",
       "2023-05-01  415.470001  417.619995  415.269989  415.510010    62122300\n",
       "2023-05-02  414.769989  414.820007  407.820007  410.839996   103998500\n",
       "\n",
       "[7619 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = yf.download(\n",
    "    TICKER_TO_PREDICT,\n",
    "    end=(TRAIN_DATA_END_DATE + datetime.timedelta(1)).strftime(\"%Y-%m-%d\"),\n",
    "    progress=False,\n",
    ")\n",
    "df.drop(columns=[\"Adj Close\"], inplace=True)\n",
    "df.rename(\n",
    "    columns={col: f\"{TICKER_TO_PREDICT}_{col}\" for col in df.columns}, inplace=True\n",
    ")\n",
    "CLOSE_NAME = f\"{TICKER_TO_PREDICT}_Close\"\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding technical indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY_Open</th>\n",
       "      <th>SPY_High</th>\n",
       "      <th>SPY_Low</th>\n",
       "      <th>SPY_Close</th>\n",
       "      <th>SPY_Volume</th>\n",
       "      <th>SPY_Close_RSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-02-18</th>\n",
       "      <td>43.937500</td>\n",
       "      <td>43.937500</td>\n",
       "      <td>42.812500</td>\n",
       "      <td>43.406250</td>\n",
       "      <td>378100</td>\n",
       "      <td>31.343145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-19</th>\n",
       "      <td>43.406250</td>\n",
       "      <td>43.562500</td>\n",
       "      <td>43.343750</td>\n",
       "      <td>43.562500</td>\n",
       "      <td>34900</td>\n",
       "      <td>36.183605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-22</th>\n",
       "      <td>43.687500</td>\n",
       "      <td>43.781250</td>\n",
       "      <td>43.562500</td>\n",
       "      <td>43.718750</td>\n",
       "      <td>513600</td>\n",
       "      <td>40.686975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-23</th>\n",
       "      <td>43.843750</td>\n",
       "      <td>43.875000</td>\n",
       "      <td>43.468750</td>\n",
       "      <td>43.687500</td>\n",
       "      <td>373700</td>\n",
       "      <td>40.077825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-24</th>\n",
       "      <td>43.718750</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>43.718750</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>26300</td>\n",
       "      <td>53.556588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-26</th>\n",
       "      <td>406.720001</td>\n",
       "      <td>407.839996</td>\n",
       "      <td>403.779999</td>\n",
       "      <td>404.359985</td>\n",
       "      <td>80447000</td>\n",
       "      <td>45.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>407.000000</td>\n",
       "      <td>412.690002</td>\n",
       "      <td>406.739990</td>\n",
       "      <td>412.410004</td>\n",
       "      <td>92968400</td>\n",
       "      <td>57.205268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28</th>\n",
       "      <td>411.489990</td>\n",
       "      <td>415.940002</td>\n",
       "      <td>411.429993</td>\n",
       "      <td>415.929993</td>\n",
       "      <td>89335600</td>\n",
       "      <td>61.078657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>415.470001</td>\n",
       "      <td>417.619995</td>\n",
       "      <td>415.269989</td>\n",
       "      <td>415.510010</td>\n",
       "      <td>62122300</td>\n",
       "      <td>60.376485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>414.769989</td>\n",
       "      <td>414.820007</td>\n",
       "      <td>407.820007</td>\n",
       "      <td>410.839996</td>\n",
       "      <td>103998500</td>\n",
       "      <td>53.070503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7606 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SPY_Open    SPY_High     SPY_Low   SPY_Close  SPY_Volume   \n",
       "Date                                                                     \n",
       "1993-02-18   43.937500   43.937500   42.812500   43.406250      378100  \\\n",
       "1993-02-19   43.406250   43.562500   43.343750   43.562500       34900   \n",
       "1993-02-22   43.687500   43.781250   43.562500   43.718750      513600   \n",
       "1993-02-23   43.843750   43.875000   43.468750   43.687500      373700   \n",
       "1993-02-24   43.718750   44.250000   43.718750   44.250000       26300   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-04-26  406.720001  407.839996  403.779999  404.359985    80447000   \n",
       "2023-04-27  407.000000  412.690002  406.739990  412.410004    92968400   \n",
       "2023-04-28  411.489990  415.940002  411.429993  415.929993    89335600   \n",
       "2023-05-01  415.470001  417.619995  415.269989  415.510010    62122300   \n",
       "2023-05-02  414.769989  414.820007  407.820007  410.839996   103998500   \n",
       "\n",
       "            SPY_Close_RSI  \n",
       "Date                       \n",
       "1993-02-18      31.343145  \n",
       "1993-02-19      36.183605  \n",
       "1993-02-22      40.686975  \n",
       "1993-02-23      40.077825  \n",
       "1993-02-24      53.556588  \n",
       "...                   ...  \n",
       "2023-04-26      45.737663  \n",
       "2023-04-27      57.205268  \n",
       "2023-04-28      61.078657  \n",
       "2023-05-01      60.376485  \n",
       "2023-05-02      53.070503  \n",
       "\n",
       "[7606 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[f\"{CLOSE_NAME}_RSI\"] = RSIIndicator(df[CLOSE_NAME], window=14).rsi()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the indicator ticker data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQQ Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "^TNX Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "^VIX Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "CL=F Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for ticker in INDICATOR_TICKERS:\n",
    "    ticker_data = yf.download(ticker, progress=False)\n",
    "    print(ticker, ticker_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SPY_Open', 'SPY_High', 'SPY_Low', 'SPY_Close', 'SPY_Volume',\n",
      "       'SPY_Close_RSI', 'QQQ_Close', '^TNX_Close', '^VIX_Close', 'CL=F_Close'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY_Open</th>\n",
       "      <th>SPY_High</th>\n",
       "      <th>SPY_Low</th>\n",
       "      <th>SPY_Close</th>\n",
       "      <th>SPY_Volume</th>\n",
       "      <th>SPY_Close_RSI</th>\n",
       "      <th>QQQ_Close</th>\n",
       "      <th>^TNX_Close</th>\n",
       "      <th>^VIX_Close</th>\n",
       "      <th>CL=F_Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-08-23</th>\n",
       "      <td>149.812500</td>\n",
       "      <td>151.281250</td>\n",
       "      <td>149.281250</td>\n",
       "      <td>150.843750</td>\n",
       "      <td>5483200</td>\n",
       "      <td>60.811526</td>\n",
       "      <td>97.062500</td>\n",
       "      <td>5.725</td>\n",
       "      <td>17.379999</td>\n",
       "      <td>32.049999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-24</th>\n",
       "      <td>151.156250</td>\n",
       "      <td>151.500000</td>\n",
       "      <td>150.500000</td>\n",
       "      <td>151.312500</td>\n",
       "      <td>4529000</td>\n",
       "      <td>62.225237</td>\n",
       "      <td>98.562500</td>\n",
       "      <td>5.716</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>31.629999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-25</th>\n",
       "      <td>151.156250</td>\n",
       "      <td>151.625000</td>\n",
       "      <td>150.937500</td>\n",
       "      <td>151.250000</td>\n",
       "      <td>2822200</td>\n",
       "      <td>61.904574</td>\n",
       "      <td>98.031250</td>\n",
       "      <td>5.721</td>\n",
       "      <td>16.530001</td>\n",
       "      <td>32.049999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-28</th>\n",
       "      <td>151.250000</td>\n",
       "      <td>152.906250</td>\n",
       "      <td>151.250000</td>\n",
       "      <td>151.765625</td>\n",
       "      <td>5518700</td>\n",
       "      <td>63.572401</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>5.766</td>\n",
       "      <td>16.540001</td>\n",
       "      <td>32.869999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-29</th>\n",
       "      <td>151.437500</td>\n",
       "      <td>151.875000</td>\n",
       "      <td>150.906250</td>\n",
       "      <td>151.796875</td>\n",
       "      <td>3561900</td>\n",
       "      <td>63.676195</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.808</td>\n",
       "      <td>16.889999</td>\n",
       "      <td>32.720001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-26</th>\n",
       "      <td>406.720001</td>\n",
       "      <td>407.839996</td>\n",
       "      <td>403.779999</td>\n",
       "      <td>404.359985</td>\n",
       "      <td>80447000</td>\n",
       "      <td>45.737663</td>\n",
       "      <td>311.869995</td>\n",
       "      <td>3.432</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>74.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>407.000000</td>\n",
       "      <td>412.690002</td>\n",
       "      <td>406.739990</td>\n",
       "      <td>412.410004</td>\n",
       "      <td>92968400</td>\n",
       "      <td>57.205268</td>\n",
       "      <td>320.350006</td>\n",
       "      <td>3.528</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>74.760002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28</th>\n",
       "      <td>411.489990</td>\n",
       "      <td>415.940002</td>\n",
       "      <td>411.429993</td>\n",
       "      <td>415.929993</td>\n",
       "      <td>89335600</td>\n",
       "      <td>61.078657</td>\n",
       "      <td>322.559998</td>\n",
       "      <td>3.452</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>76.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>415.470001</td>\n",
       "      <td>417.619995</td>\n",
       "      <td>415.269989</td>\n",
       "      <td>415.510010</td>\n",
       "      <td>62122300</td>\n",
       "      <td>60.376485</td>\n",
       "      <td>322.190002</td>\n",
       "      <td>3.574</td>\n",
       "      <td>16.080000</td>\n",
       "      <td>75.660004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>414.769989</td>\n",
       "      <td>414.820007</td>\n",
       "      <td>407.820007</td>\n",
       "      <td>410.839996</td>\n",
       "      <td>103998500</td>\n",
       "      <td>53.070503</td>\n",
       "      <td>319.380005</td>\n",
       "      <td>3.439</td>\n",
       "      <td>17.780001</td>\n",
       "      <td>71.660004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5688 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SPY_Open    SPY_High     SPY_Low   SPY_Close  SPY_Volume   \n",
       "Date                                                                     \n",
       "2000-08-23  149.812500  151.281250  149.281250  150.843750     5483200  \\\n",
       "2000-08-24  151.156250  151.500000  150.500000  151.312500     4529000   \n",
       "2000-08-25  151.156250  151.625000  150.937500  151.250000     2822200   \n",
       "2000-08-28  151.250000  152.906250  151.250000  151.765625     5518700   \n",
       "2000-08-29  151.437500  151.875000  150.906250  151.796875     3561900   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-04-26  406.720001  407.839996  403.779999  404.359985    80447000   \n",
       "2023-04-27  407.000000  412.690002  406.739990  412.410004    92968400   \n",
       "2023-04-28  411.489990  415.940002  411.429993  415.929993    89335600   \n",
       "2023-05-01  415.470001  417.619995  415.269989  415.510010    62122300   \n",
       "2023-05-02  414.769989  414.820007  407.820007  410.839996   103998500   \n",
       "\n",
       "            SPY_Close_RSI   QQQ_Close  ^TNX_Close  ^VIX_Close  CL=F_Close  \n",
       "Date                                                                       \n",
       "2000-08-23      60.811526   97.062500       5.725   17.379999   32.049999  \n",
       "2000-08-24      62.225237   98.562500       5.716   17.040001   31.629999  \n",
       "2000-08-25      61.904574   98.031250       5.721   16.530001   32.049999  \n",
       "2000-08-28      63.572401   98.500000       5.766   16.540001   32.869999  \n",
       "2000-08-29      63.676195   99.000000       5.808   16.889999   32.720001  \n",
       "...                   ...         ...         ...         ...         ...  \n",
       "2023-04-26      45.737663  311.869995       3.432   18.840000   74.300003  \n",
       "2023-04-27      57.205268  320.350006       3.528   17.030001   74.760002  \n",
       "2023-04-28      61.078657  322.559998       3.452   15.780000   76.779999  \n",
       "2023-05-01      60.376485  322.190002       3.574   16.080000   75.660004  \n",
       "2023-05-02      53.070503  319.380005       3.439   17.780001   71.660004  \n",
       "\n",
       "[5688 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RELEVANT_COLS = [\"Close\"]\n",
    "\n",
    "for ticker in INDICATOR_TICKERS:\n",
    "    ticker_data = yf.download(ticker, progress=False)\n",
    "    relevant_data = ticker_data[RELEVANT_COLS]\n",
    "    relevant_data = relevant_data.rename(\n",
    "        columns={col: f\"{ticker}_{col}\" for col in RELEVANT_COLS}\n",
    "    )\n",
    "    # Only join if the columns aren't already present\n",
    "    if len(set(df.columns).intersection(set(relevant_data.columns))) == 0:\n",
    "        df = df.join(relevant_data)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "print(df.columns)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offsetting the data and adding target values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of sequences to feed the RNN\n",
    "SEQUENCE_LEN = 60\n",
    "# Number of periods (days if data is daily) in the future to predict\n",
    "PREDICTION_PERIOD_OFFSET = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(current, future):\n",
    "    return int(float(future) > float(current))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY_Close</th>\n",
       "      <th>SPY_Close_Future</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-08-23</th>\n",
       "      <td>150.843750</td>\n",
       "      <td>142.687500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-24</th>\n",
       "      <td>151.312500</td>\n",
       "      <td>145.281250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-25</th>\n",
       "      <td>151.250000</td>\n",
       "      <td>144.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-28</th>\n",
       "      <td>151.765625</td>\n",
       "      <td>142.406250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-29</th>\n",
       "      <td>151.796875</td>\n",
       "      <td>143.156250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-28</th>\n",
       "      <td>395.600006</td>\n",
       "      <td>404.359985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29</th>\n",
       "      <td>401.350006</td>\n",
       "      <td>412.410004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30</th>\n",
       "      <td>403.700012</td>\n",
       "      <td>415.929993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>409.390015</td>\n",
       "      <td>415.510010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>410.950012</td>\n",
       "      <td>410.839996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5668 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             SPY_Close  SPY_Close_Future  Target\n",
       "Date                                            \n",
       "2000-08-23  150.843750        142.687500       0\n",
       "2000-08-24  151.312500        145.281250       0\n",
       "2000-08-25  151.250000        144.250000       0\n",
       "2000-08-28  151.765625        142.406250       0\n",
       "2000-08-29  151.796875        143.156250       0\n",
       "...                ...               ...     ...\n",
       "2023-03-28  395.600006        404.359985       1\n",
       "2023-03-29  401.350006        412.410004       1\n",
       "2023-03-30  403.700012        415.929993       1\n",
       "2023-03-31  409.390015        415.510010       1\n",
       "2023-04-03  410.950012        410.839996       0\n",
       "\n",
       "[5668 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[f\"{CLOSE_NAME}_Future\"] = df[CLOSE_NAME].shift(-1 * PREDICTION_PERIOD_OFFSET)\n",
    "df.dropna(inplace=True)\n",
    "df[\"Target\"] = list(map(classify, df[CLOSE_NAME], df[f\"{CLOSE_NAME}_Future\"]))\n",
    "\n",
    "df[[CLOSE_NAME, f\"{CLOSE_NAME}_Future\", \"Target\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into training, validation and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of data to keep for the validation and test set\n",
    "NON_TRAIN_PCT = 0.2\n",
    "# The percentage of non-training data to use for the validation set (the rest is used for the test set)\n",
    "VALIDATION_TRAIN_RATIO = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY_Open</th>\n",
       "      <th>SPY_High</th>\n",
       "      <th>SPY_Low</th>\n",
       "      <th>SPY_Close</th>\n",
       "      <th>SPY_Volume</th>\n",
       "      <th>SPY_Close_RSI</th>\n",
       "      <th>QQQ_Close</th>\n",
       "      <th>^TNX_Close</th>\n",
       "      <th>^VIX_Close</th>\n",
       "      <th>CL=F_Close</th>\n",
       "      <th>SPY_Close_Future</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-08-23</th>\n",
       "      <td>149.812500</td>\n",
       "      <td>151.281250</td>\n",
       "      <td>149.281250</td>\n",
       "      <td>150.843750</td>\n",
       "      <td>5483200</td>\n",
       "      <td>60.811526</td>\n",
       "      <td>97.062500</td>\n",
       "      <td>5.725</td>\n",
       "      <td>17.379999</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>142.687500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-24</th>\n",
       "      <td>151.156250</td>\n",
       "      <td>151.500000</td>\n",
       "      <td>150.500000</td>\n",
       "      <td>151.312500</td>\n",
       "      <td>4529000</td>\n",
       "      <td>62.225237</td>\n",
       "      <td>98.562500</td>\n",
       "      <td>5.716</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>145.281250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-25</th>\n",
       "      <td>151.156250</td>\n",
       "      <td>151.625000</td>\n",
       "      <td>150.937500</td>\n",
       "      <td>151.250000</td>\n",
       "      <td>2822200</td>\n",
       "      <td>61.904574</td>\n",
       "      <td>98.031250</td>\n",
       "      <td>5.721</td>\n",
       "      <td>16.530001</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>144.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-28</th>\n",
       "      <td>151.250000</td>\n",
       "      <td>152.906250</td>\n",
       "      <td>151.250000</td>\n",
       "      <td>151.765625</td>\n",
       "      <td>5518700</td>\n",
       "      <td>63.572401</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>5.766</td>\n",
       "      <td>16.540001</td>\n",
       "      <td>32.869999</td>\n",
       "      <td>142.406250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-29</th>\n",
       "      <td>151.437500</td>\n",
       "      <td>151.875000</td>\n",
       "      <td>150.906250</td>\n",
       "      <td>151.796875</td>\n",
       "      <td>3561900</td>\n",
       "      <td>63.676195</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.808</td>\n",
       "      <td>16.889999</td>\n",
       "      <td>32.720001</td>\n",
       "      <td>143.156250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-28</th>\n",
       "      <td>395.769989</td>\n",
       "      <td>396.489990</td>\n",
       "      <td>393.690002</td>\n",
       "      <td>395.600006</td>\n",
       "      <td>62871700</td>\n",
       "      <td>49.308792</td>\n",
       "      <td>307.119995</td>\n",
       "      <td>3.564</td>\n",
       "      <td>19.969999</td>\n",
       "      <td>73.199997</td>\n",
       "      <td>404.359985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29</th>\n",
       "      <td>399.929993</td>\n",
       "      <td>401.600006</td>\n",
       "      <td>398.679993</td>\n",
       "      <td>401.350006</td>\n",
       "      <td>77497900</td>\n",
       "      <td>55.088303</td>\n",
       "      <td>312.720001</td>\n",
       "      <td>3.566</td>\n",
       "      <td>19.120001</td>\n",
       "      <td>72.970001</td>\n",
       "      <td>412.410004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30</th>\n",
       "      <td>404.089996</td>\n",
       "      <td>404.350006</td>\n",
       "      <td>401.760010</td>\n",
       "      <td>403.700012</td>\n",
       "      <td>69840000</td>\n",
       "      <td>57.234351</td>\n",
       "      <td>315.679993</td>\n",
       "      <td>3.551</td>\n",
       "      <td>19.020000</td>\n",
       "      <td>74.370003</td>\n",
       "      <td>415.929993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>404.660004</td>\n",
       "      <td>409.700012</td>\n",
       "      <td>404.549988</td>\n",
       "      <td>409.390015</td>\n",
       "      <td>112062600</td>\n",
       "      <td>61.972472</td>\n",
       "      <td>320.929993</td>\n",
       "      <td>3.494</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>75.669998</td>\n",
       "      <td>415.510010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>408.850006</td>\n",
       "      <td>411.369995</td>\n",
       "      <td>408.440002</td>\n",
       "      <td>410.950012</td>\n",
       "      <td>67391100</td>\n",
       "      <td>63.177025</td>\n",
       "      <td>320.149994</td>\n",
       "      <td>3.430</td>\n",
       "      <td>18.549999</td>\n",
       "      <td>80.419998</td>\n",
       "      <td>410.839996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5668 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SPY_Open    SPY_High     SPY_Low   SPY_Close  SPY_Volume   \n",
       "Date                                                                     \n",
       "2000-08-23  149.812500  151.281250  149.281250  150.843750     5483200  \\\n",
       "2000-08-24  151.156250  151.500000  150.500000  151.312500     4529000   \n",
       "2000-08-25  151.156250  151.625000  150.937500  151.250000     2822200   \n",
       "2000-08-28  151.250000  152.906250  151.250000  151.765625     5518700   \n",
       "2000-08-29  151.437500  151.875000  150.906250  151.796875     3561900   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-03-28  395.769989  396.489990  393.690002  395.600006    62871700   \n",
       "2023-03-29  399.929993  401.600006  398.679993  401.350006    77497900   \n",
       "2023-03-30  404.089996  404.350006  401.760010  403.700012    69840000   \n",
       "2023-03-31  404.660004  409.700012  404.549988  409.390015   112062600   \n",
       "2023-04-03  408.850006  411.369995  408.440002  410.950012    67391100   \n",
       "\n",
       "            SPY_Close_RSI   QQQ_Close  ^TNX_Close  ^VIX_Close  CL=F_Close   \n",
       "Date                                                                        \n",
       "2000-08-23      60.811526   97.062500       5.725   17.379999   32.049999  \\\n",
       "2000-08-24      62.225237   98.562500       5.716   17.040001   31.629999   \n",
       "2000-08-25      61.904574   98.031250       5.721   16.530001   32.049999   \n",
       "2000-08-28      63.572401   98.500000       5.766   16.540001   32.869999   \n",
       "2000-08-29      63.676195   99.000000       5.808   16.889999   32.720001   \n",
       "...                   ...         ...         ...         ...         ...   \n",
       "2023-03-28      49.308792  307.119995       3.564   19.969999   73.199997   \n",
       "2023-03-29      55.088303  312.720001       3.566   19.120001   72.970001   \n",
       "2023-03-30      57.234351  315.679993       3.551   19.020000   74.370003   \n",
       "2023-03-31      61.972472  320.929993       3.494   18.700001   75.669998   \n",
       "2023-04-03      63.177025  320.149994       3.430   18.549999   80.419998   \n",
       "\n",
       "            SPY_Close_Future  Target  \n",
       "Date                                  \n",
       "2000-08-23        142.687500       0  \n",
       "2000-08-24        145.281250       0  \n",
       "2000-08-25        144.250000       0  \n",
       "2000-08-28        142.406250       0  \n",
       "2000-08-29        143.156250       0  \n",
       "...                      ...     ...  \n",
       "2023-03-28        404.359985       1  \n",
       "2023-03-29        412.410004       1  \n",
       "2023-03-30        415.929993       1  \n",
       "2023-03-31        415.510010       1  \n",
       "2023-04-03        410.839996       0  \n",
       "\n",
       "[5668 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON-BALANCED DATA:\n",
      "TRAIN: 4535 (80.01058574453069%), NON-TRAIN: 1133 (19.989414255469303%)\n",
      "VALIDATION: 850 (14.996471418489769%), TEST: 283 (4.992942836979535%)\n"
     ]
    }
   ],
   "source": [
    "TOTAL_DF_LEN = len(df.index)\n",
    "train_split_index = -1 * int(NON_TRAIN_PCT * TOTAL_DF_LEN)\n",
    "train_df, non_train_df = df[:train_split_index], df[train_split_index:]\n",
    "\n",
    "non_train_split_index = -1 * int((1 - VALIDATION_TRAIN_RATIO) * len(non_train_df.index))\n",
    "validation_df, test_df = (\n",
    "    non_train_df[:non_train_split_index],\n",
    "    non_train_df[non_train_split_index:],\n",
    ")\n",
    "\n",
    "print(\"NON-BALANCED DATA:\")\n",
    "print(\n",
    "    f\"TRAIN: {len(train_df)} ({len(train_df) / TOTAL_DF_LEN * 100}%), NON-TRAIN: {len(non_train_df)} ({len(non_train_df) / TOTAL_DF_LEN * 100}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"VALIDATION: {len(validation_df)} ({len(validation_df) / TOTAL_DF_LEN * 100}%), TEST: {len(test_df)} ({len(test_df) / TOTAL_DF_LEN * 100}%)\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the training and non-training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df, balance=True):\n",
    "    TICKER = df.columns[0].split(\"_\")[0]\n",
    "    CLOSE_NAME = TICKER + \"_Close\"\n",
    "    df = df.drop(columns=[f\"{CLOSE_NAME}_Future\"])\n",
    "\n",
    "    # Scale the data\n",
    "    for col in df.columns:\n",
    "        if col != \"Target\":\n",
    "            df[col] = df[col].pct_change()\n",
    "            df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            df.dropna(inplace=True)\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Create the sequential data\n",
    "    sequential_data = []\n",
    "    data_queue = deque(maxlen=SEQUENCE_LEN)\n",
    "\n",
    "    for datapoint in df.values:\n",
    "        # The last column in the df will be Target. Don't include this in the list of independent features\n",
    "        data_queue.append(datapoint[:-1])\n",
    "        if len(data_queue) == SEQUENCE_LEN:\n",
    "            sequential_data.append([np.array(data_queue), datapoint[-1]])\n",
    "\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    if balance:\n",
    "        # Balance the dataset\n",
    "        buys = []\n",
    "        sells = []\n",
    "\n",
    "        for seq, target in sequential_data:\n",
    "            if target:\n",
    "                buys.append([seq, target])\n",
    "            else:\n",
    "                sells.append([seq, target])\n",
    "\n",
    "        minimum = min(len(buys), len(sells))\n",
    "\n",
    "        random.shuffle(buys)\n",
    "        random.shuffle(sells)\n",
    "\n",
    "        buys = buys[:minimum]\n",
    "        sells = sells[:minimum]\n",
    "\n",
    "        sequential_data = buys + sells\n",
    "        random.shuffle(sequential_data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BALANCED DATA:\n",
      "Train: 3374\n",
      "Validation: 428\n",
      "Test: 198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = preprocess_df(train_df)\n",
    "X_validation, y_validation = preprocess_df(validation_df)\n",
    "X_test, y_test = preprocess_df(test_df)\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "BALANCED DATA:\n",
    "Train: {len(X_train)}\n",
    "Validation: {len(X_validation)}\n",
    "Test: {len(X_test)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "106/106 [==============================] - 5s 23ms/step - loss: 0.7139 - accuracy: 0.5104 - val_loss: 0.6942 - val_accuracy: 0.4720\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 2s 19ms/step - loss: 0.7052 - accuracy: 0.5122 - val_loss: 0.6949 - val_accuracy: 0.4883\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 2s 19ms/step - loss: 0.7011 - accuracy: 0.5006 - val_loss: 0.6953 - val_accuracy: 0.4883\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 2s 20ms/step - loss: 0.6915 - accuracy: 0.5261 - val_loss: 0.6950 - val_accuracy: 0.5023\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 2s 19ms/step - loss: 0.6929 - accuracy: 0.5314 - val_loss: 0.6940 - val_accuracy: 0.5047\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 2s 19ms/step - loss: 0.6959 - accuracy: 0.5110 - val_loss: 0.6937 - val_accuracy: 0.5047\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 2s 19ms/step - loss: 0.6933 - accuracy: 0.5282 - val_loss: 0.6934 - val_accuracy: 0.5070\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 2s 21ms/step - loss: 0.6940 - accuracy: 0.5252 - val_loss: 0.6932 - val_accuracy: 0.5164\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 2s 21ms/step - loss: 0.6927 - accuracy: 0.5255 - val_loss: 0.6931 - val_accuracy: 0.5187\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 2s 20ms/step - loss: 0.6935 - accuracy: 0.5299 - val_loss: 0.6932 - val_accuracy: 0.5210\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        LSTM(20),\n",
    "        Dropout(0.3),\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation=\"gelu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(16, activation=\"gelu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=np.ceil(len(X_train) / BATCH_SIZE),\n",
    "    decay_rate=0.7,\n",
    ")\n",
    "opt = Adam(learning_rate=lr_schedule)\n",
    "model.compile(\n",
    "    optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_validation, y_validation),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 20)                2480      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 20)                0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 20)               80        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 16)                336       \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,202\n",
      "Trainable params: 3,162\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/SPY\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/SPY\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./models/SPY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"./models/SPY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits = model(X_test, training=False)\n",
    "predictions = tf.math.argmax(logits, axis=1, output_type=tf.int64)\n",
    "cf_matrix = confusion_matrix(y_test, predictions)\n",
    "cm_display = ConfusionMatrixDisplay(cf_matrix, display_labels=[\"Lower\", \"Higher\"])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Lower       0.58      0.42      0.49        99\n",
      "      Higher       0.55      0.70      0.61        99\n",
      "\n",
      "    accuracy                           0.56       198\n",
      "   macro avg       0.57      0.56      0.55       198\n",
      "weighted avg       0.57      0.56      0.55       198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits = model(X_test, training=False)\n",
    "predictions = tf.math.argmax(logits, axis=1, output_type=tf.int64)\n",
    "print(classification_report(y_test, predictions, target_names=[\"Lower\", \"Higher\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.56060606>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(X_test, training=False)\n",
    "predictions = tf.math.argmax(logits, axis=1, output_type=tf.int64)\n",
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "test_accuracy(predictions, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the entire dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5433637>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = preprocess_df(df)\n",
    "\n",
    "logits = model(X, training=False)\n",
    "predictions = tf.math.argmax(logits, axis=1, output_type=tf.int64)\n",
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "test_accuracy(predictions, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on various stock tickers (within the S&P500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ticker(TICKER):\n",
    "    df = yf.download(TICKER, progress=False)\n",
    "    df.drop(columns=[\"Adj Close\"], inplace=True)\n",
    "    df.rename(columns={col: f\"{TICKER}_{col}\" for col in df.columns}, inplace=True)\n",
    "\n",
    "    df[f\"{TICKER}_Close_RSI\"] = RSIIndicator(df[f\"{TICKER}_Close\"], window=14).rsi()\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    for ticker in INDICATOR_TICKERS:\n",
    "        ticker_data = yf.download(ticker, progress=False)\n",
    "        relevant_data = ticker_data[RELEVANT_COLS]\n",
    "        relevant_data = relevant_data.rename(\n",
    "            columns={col: f\"{ticker}_{col}\" for col in RELEVANT_COLS}\n",
    "        )\n",
    "        # Only join if the columns aren't already present\n",
    "        if len(set(df.columns).intersection(set(relevant_data.columns))) == 0:\n",
    "            df = df.join(relevant_data)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df[f\"{TICKER}_Close_Future\"] = df[f\"{TICKER}_Close\"].shift(\n",
    "        -1 * PREDICTION_PERIOD_OFFSET\n",
    "    )\n",
    "    df.dropna(inplace=True)\n",
    "    df[\"Target\"] = list(\n",
    "        map(classify, df[f\"{TICKER}_Close\"], df[f\"{TICKER}_Close_Future\"])\n",
    "    )\n",
    "\n",
    "    X, y = preprocess_df(df, balance=False)\n",
    "\n",
    "    print(\"Starting inference\")\n",
    "    start = time.time()\n",
    "    logits = model(X, training=False)\n",
    "    print(\"End of inference\")\n",
    "    print(f\"Inference took: {time.time() - start}s\")\n",
    "    predictions = tf.math.argmax(logits, axis=1, output_type=tf.int64)\n",
    "    test_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "    return test_accuracy(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference\n",
      "End of inference\n",
      "Inference took: 0.38651442527770996s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5161063>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ticker(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference\n",
      "End of inference\n",
      "Inference took: 0.3657703399658203s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5250836>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ticker(\"MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference\n",
      "End of inference\n",
      "Inference took: 0.29278111457824707s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5359408>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ticker(\"V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference\n",
      "End of inference\n",
      "Inference took: 0.3668246269226074s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5403978>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ticker(\"HD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference\n",
      "End of inference\n",
      "Inference took: 0.3689110279083252s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5222672>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ticker(\"KO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference\n",
      "End of inference\n",
      "Inference took: 0.3810429573059082s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5259637>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ticker(\"JPM\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on various stock tickers (not in the S&P500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference\n",
      "End of inference\n",
      "Inference took: 0.37306928634643555s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.522877>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ticker(\"MC.PA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference\n",
      "End of inference\n",
      "Inference took: 0.3758518695831299s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5433903>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ticker(\"TTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference\n",
      "End of inference\n",
      "Inference took: 0.3683333396911621s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5294843>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ticker(\"LIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
